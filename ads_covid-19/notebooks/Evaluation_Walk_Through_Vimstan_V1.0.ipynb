{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# One full run through"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Run through the large data set\n",
    "- Ensure full run with one click"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Your base path is at: ads_covid-19'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "if os.path.split(os.getcwd())[-1] == 'notebooks':\n",
    "    os.chdir(\"../\")\n",
    "\n",
    "'Your base path is at: ' + os.path.split(os.getcwd())[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Update all data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- close loop towards business delivery\n",
    "- process should be a one click delivery\n",
    "- move to large dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: b'From https://github.com/CSSEGISandData/COVID-19\\n   8bd11fbe..6e9880c5  master              -> origin/master\\n * [new branch]        2638-Fix-State-FIPS -> origin/2638-Fix-State-FIPS\\n   b534cb8b..81026de3  web-data            -> origin/web-data\\n'\n",
      "out: b'Updating 8bd11fbe..6e9880c5\\nFast-forward\\n README.md                                          |   11 +-\\n csse_covid_19_data/README.md                       |   19 +-\\n csse_covid_19_data/UID_ISO_FIPS_LookUp_Table.csv   |  883 +--\\n .../csse_covid_19_daily_reports/05-29-2020.csv     | 3523 +++++++++++\\n .../csse_covid_19_daily_reports/05-30-2020.csv     | 3526 +++++++++++\\n .../csse_covid_19_daily_reports/05-31-2020.csv     | 3527 +++++++++++\\n .../csse_covid_19_daily_reports/06-01-2020.csv     | 3638 +++++++++++\\n .../csse_covid_19_daily_reports/06-02-2020.csv     | 3642 +++++++++++\\n .../csse_covid_19_daily_reports/06-03-2020.csv     | 3645 +++++++++++\\n .../csse_covid_19_daily_reports/06-04-2020.csv     | 3646 +++++++++++\\n .../csse_covid_19_daily_reports/06-05-2020.csv     | 3670 +++++++++++\\n .../csse_covid_19_daily_reports/06-06-2020.csv     | 3672 +++++++++++\\n .../csse_covid_19_daily_reports/06-07-2020.csv     | 3672 +++++++++++\\n .../csse_covid_19_daily_reports/06-08-2020.csv     | 3673 +++++++++++\\n .../csse_covid_19_daily_reports/06-09-2020.csv     | 3675 +++++++++++\\n .../csse_covid_19_daily_reports/06-10-2020.csv     | 3718 +++++++++++\\n .../csse_covid_19_daily_reports/06-11-2020.csv     | 3724 +++++++++++\\n .../csse_covid_19_daily_reports_us/05-29-2020.csv  |   59 +\\n .../csse_covid_19_daily_reports_us/05-30-2020.csv  |   59 +\\n .../csse_covid_19_daily_reports_us/05-31-2020.csv  |   59 +\\n .../csse_covid_19_daily_reports_us/06-01-2020.csv  |   59 +\\n .../csse_covid_19_daily_reports_us/06-02-2020.csv  |   59 +\\n .../csse_covid_19_daily_reports_us/06-03-2020.csv  |   59 +\\n .../csse_covid_19_daily_reports_us/06-04-2020.csv  |   59 +\\n .../csse_covid_19_daily_reports_us/06-05-2020.csv  |   59 +\\n .../csse_covid_19_daily_reports_us/06-06-2020.csv  |   59 +\\n .../csse_covid_19_daily_reports_us/06-07-2020.csv  |   59 +\\n .../csse_covid_19_daily_reports_us/06-08-2020.csv  |   59 +\\n .../csse_covid_19_daily_reports_us/06-09-2020.csv  |   59 +\\n .../csse_covid_19_daily_reports_us/06-10-2020.csv  |   59 +\\n .../csse_covid_19_daily_reports_us/06-11-2020.csv  |   59 +\\n .../csse_covid_19_time_series/Errata.csv           |  407 +-\\n .../time_series_covid19_confirmed_US.csv           | 6524 ++++++++++----------\\n .../time_series_covid19_confirmed_global.csv       |  534 +-\\n .../time_series_covid19_deaths_US.csv              | 6524 ++++++++++----------\\n .../time_series_covid19_deaths_global.csv          |  534 +-\\n .../time_series_covid19_recovered_global.csv       |  508 +-\\n .../who_covid_19_sit_rep_time_series.csv           |  537 +-\\n 38 files changed, 60139 insertions(+), 8119 deletions(-)\\n create mode 100644 csse_covid_19_data/csse_covid_19_daily_reports/05-29-2020.csv\\n create mode 100644 csse_covid_19_data/csse_covid_19_daily_reports/05-30-2020.csv\\n create mode 100644 csse_covid_19_data/csse_covid_19_daily_reports/05-31-2020.csv\\n create mode 100644 csse_covid_19_data/csse_covid_19_daily_reports/06-01-2020.csv\\n create mode 100644 csse_covid_19_data/csse_covid_19_daily_reports/06-02-2020.csv\\n create mode 100644 csse_covid_19_data/csse_covid_19_daily_reports/06-03-2020.csv\\n create mode 100644 csse_covid_19_data/csse_covid_19_daily_reports/06-04-2020.csv\\n create mode 100644 csse_covid_19_data/csse_covid_19_daily_reports/06-05-2020.csv\\n create mode 100644 csse_covid_19_data/csse_covid_19_daily_reports/06-06-2020.csv\\n create mode 100644 csse_covid_19_data/csse_covid_19_daily_reports/06-07-2020.csv\\n create mode 100644 csse_covid_19_data/csse_covid_19_daily_reports/06-08-2020.csv\\n create mode 100644 csse_covid_19_data/csse_covid_19_daily_reports/06-09-2020.csv\\n create mode 100644 csse_covid_19_data/csse_covid_19_daily_reports/06-10-2020.csv\\n create mode 100644 csse_covid_19_data/csse_covid_19_daily_reports/06-11-2020.csv\\n create mode 100644 csse_covid_19_data/csse_covid_19_daily_reports_us/05-29-2020.csv\\n create mode 100644 csse_covid_19_data/csse_covid_19_daily_reports_us/05-30-2020.csv\\n create mode 100644 csse_covid_19_data/csse_covid_19_daily_reports_us/05-31-2020.csv\\n create mode 100644 csse_covid_19_data/csse_covid_19_daily_reports_us/06-01-2020.csv\\n create mode 100644 csse_covid_19_data/csse_covid_19_daily_reports_us/06-02-2020.csv\\n create mode 100644 csse_covid_19_data/csse_covid_19_daily_reports_us/06-03-2020.csv\\n create mode 100644 csse_covid_19_data/csse_covid_19_daily_reports_us/06-04-2020.csv\\n create mode 100644 csse_covid_19_data/csse_covid_19_daily_reports_us/06-05-2020.csv\\n create mode 100644 csse_covid_19_data/csse_covid_19_daily_reports_us/06-06-2020.csv\\n create mode 100644 csse_covid_19_data/csse_covid_19_daily_reports_us/06-07-2020.csv\\n create mode 100644 csse_covid_19_data/csse_covid_19_daily_reports_us/06-08-2020.csv\\n create mode 100644 csse_covid_19_data/csse_covid_19_daily_reports_us/06-09-2020.csv\\n create mode 100644 csse_covid_19_data/csse_covid_19_daily_reports_us/06-10-2020.csv\\n create mode 100644 csse_covid_19_data/csse_covid_19_daily_reports_us/06-11-2020.csv\\n'\n",
      "Number of region rows:412\n"
     ]
    }
   ],
   "source": [
    "# %load src/data/get_data.py # Load the file directly!\n",
    "# Open files\n",
    "import subprocess\n",
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "# Access websites\n",
    "import requests\n",
    "# Access json files\n",
    "import json\n",
    "\n",
    "def get_john_hopkins():\n",
    "   # Running a process using 'git' to get the data from 'cwd'\n",
    "   # shell == True the specified command will be executed through the shell.\n",
    "   # stdin, stdout and stderr specify the executed programâ€™s standard input, standard output and standard error file handles, respectively.\n",
    "   # .communicate() writes input, reads all output, and waits for the subprocess to exit.\n",
    "    git_pull = subprocess.Popen('/usr/bin/git pull' ,\n",
    "    cwd = os.path.dirname('data/raw/COVID-19/'),\n",
    "    shell = True,\n",
    "    stdout = subprocess.PIPE,\n",
    "    stderr = subprocess.PIPE)\n",
    "\n",
    "    (out, error) = git_pull.communicate()\n",
    "\n",
    "    print(\"Error: \" + str(error))\n",
    "    print(\"out: \" + str(out))\n",
    "\n",
    "\n",
    "def get_current_data_germany():\n",
    "    data = requests.get('https://services7.arcgis.com/mOBPykOjAyBO2ZKk/arcgis/rest/services/RKI_Landkreisdaten/FeatureServer/0/query?where=1%3D1&outFields=*&outSR=4326&f=json')\n",
    "\n",
    "    json_object = json.loads(data.content)\n",
    "    full_list = []\n",
    "    for pos, each_dict in enumerate(json_object['features'][:]):\n",
    "        full_list.append(each_dict['attributes'])\n",
    "\n",
    "    pd_full_list = pd.DataFrame(full_list)\n",
    "    pd_full_list.to_csv('data/raw/NPGEO/GER_state_data.csv',sep=';')\n",
    "    print('Number of region rows:' +str(pd_full_list.shape[0]))\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    get_john_hopkins()\n",
    "    get_current_data_germany()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- process the dataset(ex:John Hopkins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Number of rows stored: 37772\n"
     ]
    }
   ],
   "source": [
    "# %load src/data/process_JH_data.py\n",
    "# Process the data\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "# Relational dataset : like a key:values pair\n",
    "def store_relational_JH_data():\n",
    "    data_path = 'data/raw/COVID-19/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_confirmed_global.csv'\n",
    "    pd_raw = pd.read_csv(data_path)\n",
    "\n",
    "    pd_data_base = pd_raw.rename(columns = {'Country/Region' : 'country',\n",
    "    'Province/State' : 'state'})\n",
    "\n",
    "    pd_data_base['state'] = pd_data_base['state'].fillna('no')\n",
    "\n",
    "    pd_data_base = pd_data_base.drop(['Lat', 'Long'], axis = 1)\n",
    "\n",
    "    # stack(): From columns to set_index\n",
    "    pd_relational_model = pd_data_base.set_index(['state', 'country']) \\\n",
    "    .T \\\n",
    "    .stack(level = [0,1]) \\\n",
    "    .reset_index() \\\n",
    "    .rename(columns = {'level_0' : 'date',\n",
    "    0 : 'confirmed'},\n",
    "    )\n",
    "\n",
    "    pd_relational_model['date'] = pd_relational_model.date.astype('datetime64[ns]')\n",
    "\n",
    "    pd_relational_model.to_csv('data/processed/COVID_relational_confirmed.csv',sep = ';',index = False)\n",
    "    print(' Number of rows stored: ' + str(pd_relational_model.shape[0]))\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    store_relational_JH_data()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter and Doubling Rate Calculation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- bring in the regression function, doubling rate function etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The test slope is: [2.]\n",
      "            date state  country  confirmed  confirmed_filtered  confirmed_DR  \\\n",
      "20585 2020-06-07    no  Germany   185750.0            185747.8    448.849072   \n",
      "20586 2020-06-08    no  Germany   186109.0            186067.4    563.792615   \n",
      "20587 2020-06-09    no  Germany   186506.0            186315.6    492.385362   \n",
      "20588 2020-06-10    no  Germany   186522.0            186545.1    902.561743   \n",
      "20589 2020-06-11    no  Germany   186691.0            186774.6   2017.005405   \n",
      "\n",
      "       confirmed_filtered_DR  \n",
      "20585             460.825626  \n",
      "20586             511.340125  \n",
      "20587             655.313843  \n",
      "20588             780.026656  \n",
      "20589             812.832680  \n"
     ]
    }
   ],
   "source": [
    "# %load src/features/build_features.py\n",
    "# %load src/features/build_features.py\n",
    "# Linear regression models\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import linear_model\n",
    "reg = linear_model.LinearRegression(fit_intercept = True)\n",
    "\n",
    "from scipy import signal\n",
    "\n",
    "def get_doubling_time_via_regression(in_array):\n",
    "\n",
    "    y = np.array(in_array)\n",
    "    X = np.arange(-1,2).reshape(-1,1)\n",
    "\n",
    "    assert len(in_array) == 3\n",
    "    reg.fit(X,y)\n",
    "    intercept = reg.intercept_\n",
    "    slope = reg.coef_\n",
    "\n",
    "    return intercept/slope\n",
    "\n",
    "# Whenever the Python interpreter reads a source file, it does two things:\n",
    "# it sets a few special variables like __name__, and then\n",
    "# it executes all of the code found in the file.\n",
    "# It's as if the interpreter inserts this at the top\n",
    "# of your module when run as the main program.\n",
    "# __name__ == \"__main__\"\n",
    "#if __name__ == '__main__':\n",
    "    #test_data = np.array([2,4,6])\n",
    "    #result = get_doubling_time_via_regression(test_data)\n",
    "    #print('The test slope is: ' + str(result))\n",
    "\n",
    "def savgol_filter(df_input, column ='confirmed', window = 5):\n",
    "    ''' Filter the data'''\n",
    "    degree = 1\n",
    "    df_result = df_input\n",
    "\n",
    "    filter_in = df_input[column].fillna(0) # Fill NA/NaN values using the specified method\n",
    "\n",
    "    result = signal.savgol_filter(np.array(filter_in),\n",
    "                                 window,\n",
    "                                 degree)\n",
    "    df_result[str(column+'_filtered')] = result\n",
    "    return df_result\n",
    "\n",
    "def rolling_reg(df_input,col='confirmed'):\n",
    "    ''' Rolling Regression to approximate the doubling time'''\n",
    "    ''' Connected to -> get_doubling_time_via_regression'''\n",
    "    days_back = 3\n",
    "    result = df_input[col].rolling(\n",
    "                window = days_back,\n",
    "                min_periods = days_back).apply(get_doubling_time_via_regression, raw = False)\n",
    "    return result\n",
    "\n",
    "def calc_filtered_data(df_input, filter_on = 'confirmed'):\n",
    "    ''' This function does all the merging of the new filtered data'''\n",
    "    ''' Connected to -> savgol_filter'''\n",
    "    # Set creates an unordered list of the given parameters\n",
    "    must_contain = set(['state', 'country', filter_on])\n",
    "    # Asserting whether state and country included in df_input\n",
    "    assert must_contain.issubset(set(df_input.columns)), 'comment after a comma is accepted'\n",
    "\n",
    "    df_output = df_input.copy()\n",
    "    pd_filtered_result = df_output[['state', 'country', filter_on]].groupby(['state', 'country']).apply(savgol_filter)\n",
    "    df_output = pd.merge(df_output, pd_filtered_result[[str(filter_on + '_filtered')]], left_index = True, right_index = True, how = 'left')\n",
    "    return df_output.copy()\n",
    "\n",
    "def calc_doubling_rate(df_input, filter_on = 'confirmed'):\n",
    "    ''' Connected to -> rolling_reg'''\n",
    "    must_contain = set(['state', 'country', filter_on])\n",
    "    assert must_contain.issubset(set(df_input.columns)), 'comment after a comma is accepted'\n",
    "\n",
    "    # Apply rolling_reg to the column 'confirmed' on states of countries\n",
    "    pd_DR_result = df_input.groupby(['state', 'country']).apply(rolling_reg, filter_on).reset_index()\n",
    "\n",
    "    pd_DR_result = pd_DR_result.rename(columns = {filter_on : filter_on+'_DR', 'level_2' :'index'})\n",
    "\n",
    "    df_output = pd.merge(df_input, pd_DR_result[['index', str(filter_on + '_DR')]], left_index = True, right_on = ['index'], how = 'left')\n",
    "    df_output = df_output.drop(columns = ['index'])\n",
    "\n",
    "    return df_output\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    test_data_reg = np.array([2,4,6])\n",
    "    result = get_doubling_time_via_regression(test_data_reg)\n",
    "    print('The test slope is: ' + str(result))\n",
    "\n",
    "    pd_JH_data = pd.read_csv('data/processed/COVID_relational_confirmed.csv', sep = ';', parse_dates = [0])\n",
    "    pd_JH_data = pd_JH_data.sort_values('date', ascending = True).copy()\n",
    "\n",
    "    pd_result_larg = calc_filtered_data(pd_JH_data)\n",
    "    pd_result_larg = calc_doubling_rate(pd_result_larg)\n",
    "    # overwrites the parameter 'filter_on'\n",
    "    pd_result_larg = calc_doubling_rate(pd_result_larg, 'confirmed_filtered')\n",
    "\n",
    "    mask = pd_result_larg['confirmed'] > 100\n",
    "    pd_result_larg['confirmed_filtered_DR'] = pd_result_larg['confirmed_filtered_DR'].where(mask, other = np.NaN)\n",
    "    pd_result_larg.to_csv('data/processed/COVID_final_set.csv', sep = ';', index = False)\n",
    "    print(pd_result_larg[pd_result_larg['country'] == 'Germany'].tail())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visual Board"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- dash board with full list of countries (>=100)\n",
    "- all features(ex.:filtered data, doubling rate) from the data needs to be shown in dashboard\n",
    "- graph starts with 100 confirmed cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/vimstan/Desktop/Data Science/Vimstan_Covid19/ads_covid-19\n",
      "Running on http://127.0.0.1:8050/\n",
      "Running on http://127.0.0.1:8050/\n",
      "Debugger PIN: 066-136-227\n",
      "Debugger PIN: 066-136-227\n",
      " * Serving Flask app \"__main__\" (lazy loading)\n",
      " * Environment: production\n",
      "   WARNING: This is a development server. Do not use it in a production deployment.\n",
      "   Use a production WSGI server instead.\n",
      " * Debug mode: on\n"
     ]
    }
   ],
   "source": [
    "# %load ../src/visualization/visualize.py\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import dash\n",
    "dash.__version__\n",
    "import dash_core_components as dcc\n",
    "import dash_html_components as html\n",
    "from dash.dependencies import Input, Output, State\n",
    "\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "import os\n",
    "# Get current working directory\n",
    "print(os.getcwd())\n",
    "df_input_large = pd.read_csv('data/processed/COVID_final_set.csv',sep=';')\n",
    "\n",
    "fig = go.Figure()\n",
    "app = dash.Dash()\n",
    "app.layout = html.Div([ # In Markdown one can add text for the dashboard\n",
    "dcc.Markdown('''\n",
    "# Applied Data Science on COVID-19 data\n",
    "Goals of the project:\n",
    "- teach data science by applying a cross industry standard process\n",
    "- automated data gathering, data transformations, filtering\n",
    "- apply machine learning to approximate the doubling Timeline\n",
    "- static deployment of the dashboard\n",
    "\n",
    "\n",
    "'''),\n",
    "\n",
    "dcc.Markdown('''\n",
    "## Select different countries for visualization\n",
    "'''),\n",
    "\n",
    "dcc.Dropdown(# This is the selection area of the countries\n",
    "id = 'country_drop_down',\n",
    "options = [{'label' : each, 'value' : each} for each in df_input_large['country'].unique()],# check if countries are not repeated\n",
    "value = ['US', 'Germany', 'Italy'],# pre-selected\n",
    "multi = True # Many options can be chosen\n",
    "),\n",
    "\n",
    "dcc.Markdown('''\n",
    "## Features\n",
    "'''),\n",
    "\n",
    "dcc.Dropdown(\n",
    "id = 'doubling_time',\n",
    "options = [\n",
    "{'label' : 'Timeline Confirmed', 'value' : 'confirmed'},\n",
    "{'label' : 'Timeline Confirmed Filtered', 'value' : 'confirmed_filtered'},\n",
    "{'label' : 'Timeline Doubling Rate', 'value' : 'confirmed_DR'},\n",
    "{'label' : 'Timeline Doubling Rate Filtered', 'value' : 'confirmed_filtered_DR'},\n",
    "],\n",
    "value = 'confirmed',\n",
    "multi = False\n",
    "),\n",
    "dcc.Graph(figure = fig, id = 'main_window_slope')\n",
    "])\n",
    "\n",
    "@app.callback(\n",
    "Output('main_window_slope', 'figure'), # property -> figure\n",
    "[Input('country_drop_down', 'value'), # property -> value\n",
    "Input('doubling_time', 'value')])\n",
    "\n",
    "def update_figure(country_list, show_doubling):\n",
    "    if 'confirmed_DR' in show_doubling:\n",
    "        my_yaxis = {'type' : \"log\",\n",
    "        'title' : 'Approximated doubling rate over 3 days (larger numbers are better)'\n",
    "        }\n",
    "    else:\n",
    "        my_yaxis = {'type' : \"log\",\n",
    "        'title':'Confirmed infected people (source johns hopkins csse, log-scale)'\n",
    "        }\n",
    "\n",
    "    traces = [] # creating a list\n",
    "    for each in country_list:\n",
    "        df_plot = df_input_large[df_input_large['country'] == each]\n",
    "\n",
    "        if show_doubling == 'confirmed_filtered_DR':\n",
    "            # aggregate per date and country\n",
    "            df_plot = df_plot[['state', 'country', 'confirmed', 'confirmed_filtered', 'confirmed_DR', 'confirmed_filtered_DR', 'date']].groupby(['country', 'date']).agg(np.mean).reset_index()\n",
    "        else: # confimred data -> therefore add all the cases\n",
    "            df_plot = df_plot[['state','country','confirmed','confirmed_filtered','confirmed_DR','confirmed_filtered_DR','date']].groupby(['country','date']).agg(np.sum).reset_index()\n",
    "\n",
    "        traces.append(dict(x = df_plot.date,\n",
    "                           y = df_plot[show_doubling],\n",
    "                           mode = 'markers+lines',\n",
    "                           opacity = 0.9,\n",
    "                           name = each,\n",
    "                          )\n",
    "                       )\n",
    "    return {\n",
    "    'data' : traces,\n",
    "    'layout' : dict(\n",
    "    width = 1280,\n",
    "    height = 720,\n",
    "\n",
    "    xaxis={'title':'Timeline',\n",
    "            'tickangle':-45,\n",
    "            'nticks':20,\n",
    "            'tickfont':dict(size=14,color=\"#7f7f7f\"),\n",
    "          },\n",
    "    yaxis = my_yaxis\n",
    "    )\n",
    "}\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # set debug to true to ensure we don't have to keep refreshing the server every time we make some changes\n",
    "    app.run_server(debug=True, use_reloader=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
